{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f249c3a7-e59d-43df-8d29-2ede58c14f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\atkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\atkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\atkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\atkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\atkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\atkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\atkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\atkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\atkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\atkar\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dca05e69-d1f4-4790-81c6-dcc498334e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 107585\n"
     ]
    }
   ],
   "source": [
    "with open(\"book.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read().lower()\n",
    "\n",
    "text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
    "text = re.sub(r'\\s+', ' ', text).strip()\n",
    "words = text.split()\n",
    "\n",
    "print(f\"Total words: {len(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e46cbdb7-ae98-4f18-8423-9f7558a72147",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = Counter(words)\n",
    "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "VOCAB_SIZE = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d077860e-2619-42f2-9db3-7ecde96d4634",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 5\n",
    "sequences = []\n",
    "for i in range(SEQUENCE_LENGTH, len(words)):\n",
    "    seq = words[i - SEQUENCE_LENGTH:i + 1]\n",
    "    sequences.append([word_to_idx[word] for word in seq])\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:, :-1], sequences[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b9528be-5eef-4ec5-81dd-407cb9f0e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.LongTensor(X)\n",
    "        self.y = torch.LongTensor(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = WordDataset(X_train, y_train)\n",
    "test_dataset = WordDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "838ae9b6-583f-466a-9d1e-814b1ba64b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextWordModel(\n",
       "  (embedding): Embedding(10409, 50)\n",
       "  (lstm): LSTM(50, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=10409, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NextWordModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(NextWordModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Use output of last timestep\n",
    "        return out\n",
    "\n",
    "model = NextWordModel(VOCAB_SIZE, embed_dim=50, hidden_dim=128)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9842916-76cd-4446-badb-4209e24aa028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.7638\n",
      "Epoch 2, Loss: 6.0119\n",
      "Epoch 3, Loss: 5.6125\n",
      "Epoch 4, Loss: 5.2846\n",
      "Epoch 5, Loss: 4.9884\n",
      "Epoch 6, Loss: 4.7190\n",
      "Epoch 7, Loss: 4.4679\n",
      "Epoch 8, Loss: 4.2329\n",
      "Epoch 9, Loss: 4.0128\n",
      "Epoch 10, Loss: 3.8052\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88e282bd-74cb-4b2c-b50f-e77aa121c16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert Seed:  To Sherlock Holmes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top predictions: ['was', 'had', 'and']\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(model, seed_text, top_k=3):\n",
    "    model.eval()\n",
    "    tokens = [word_to_idx.get(w, 0) for w in seed_text.lower().split()]\n",
    "    tokens = tokens[-SEQUENCE_LENGTH:]\n",
    "    if len(tokens) < SEQUENCE_LENGTH:\n",
    "        tokens = [0] * (SEQUENCE_LENGTH - len(tokens)) + tokens\n",
    "    input_tensor = torch.LongTensor(tokens).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probs = torch.softmax(output, dim=1).cpu().numpy().flatten()\n",
    "        top_indices = np.argsort(probs)[-top_k:][::-1]\n",
    "        return [idx_to_word[idx] for idx in top_indices]\n",
    "\n",
    "seed = input(\"Insert Seed: \")\n",
    "print(\"Top predictions:\", predict_next_word(model, seed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
